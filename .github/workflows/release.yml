name: Release

on:
  push:
    branches: [main]
    tags: ['v*']
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: release-${{ github.ref }}
  cancel-in-progress: false

env:
  IMAGE_NAME: kb-api

jobs:
  # ================================
  # Build & Push to ACR
  # ================================
  build_and_push:
    name: Build & Push to ACR
    runs-on: ubuntu-latest
    environment: production
    # CI runs in parallel via ci.yml on push to main
    outputs:
      image_tag: ${{ steps.meta.outputs.tags }}
      image_digest: ${{ steps.build.outputs.digest }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Azure Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ secrets.ACR_LOGIN_SERVER }}
          username: ${{ secrets.ACR_USERNAME }}
          password: ${{ secrets.ACR_PASSWORD }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ secrets.ACR_LOGIN_SERVER }}/${{ secrets.ACR_REPOSITORY }}
          tags: |
            type=ref,event=branch
            type=ref,event=tag
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push image
        id: build
        uses: docker/build-push-action@v6
        with:
          context: .
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            VERSION=${{ github.ref_name }}
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}

      - name: Image digest
        run: echo "Image digest is ${{ steps.build.outputs.digest }}"

  # ================================
  # Deploy to Internal Server via Jump Host
  # ================================
  deploy_internal:
    name: Deploy to Internal Server
    runs-on: ubuntu-latest
    needs: build_and_push
    environment:
      name: production
    steps:
      # Login to ACR (for docker pull on internal server)
      - name: Configure ACR credentials
        run: |
          echo "ACR_LOGIN_SERVER=${{ secrets.ACR_LOGIN_SERVER }}" >> $GITHUB_ENV
          echo "ACR_REPOSITORY=${{ secrets.ACR_REPOSITORY }}" >> $GITHUB_ENV
          echo "ACR_USERNAME=${{ secrets.ACR_USERNAME }}" >> $GITHUB_ENV
          echo "ACR_PASSWORD=${{ secrets.ACR_PASSWORD }}" >> $GITHUB_ENV

      # Deploy to internal server via SSH ProxyJump
      - name: Deploy to Internal Server
        uses: appleboy/ssh-action@v1.0.3
        env:
          ACR_LOGIN_SERVER: ${{ secrets.ACR_LOGIN_SERVER }}
          ACR_REPOSITORY: ${{ secrets.ACR_REPOSITORY }}
          ACR_USERNAME: ${{ secrets.ACR_USERNAME }}
          ACR_PASSWORD: ${{ secrets.ACR_PASSWORD }}
          IMAGE_NAME: kb-api
          DOPPLER_TOKEN: ${{ secrets.DOPPLER_TOKEN }}
        with:
          host: ${{ secrets.INTERNAL_SSH_HOST }}
          username: ${{ secrets.INTERNAL_SSH_USER }}
          port: ${{ secrets.INTERNAL_SSH_PORT }}
          proxy_host: ${{ secrets.DEPLOY_SSH_HOST }}
          proxy_username: ${{ secrets.DEPLOY_SSH_USER }}
          proxy_port: ${{ secrets.DEPLOY_SSH_PORT }}
          proxy_key: ${{ secrets.DEPLOY_SSH_KEY }}
          key: ${{ secrets.DEPLOY_SSH_KEY }}
          envs: ACR_LOGIN_SERVER,ACR_REPOSITORY,ACR_USERNAME,ACR_PASSWORD,IMAGE_NAME,DOPPLER_TOKEN
          script: |
            set -euo pipefail

            echo "=== Deploying KB API to Internal Server ==="
            echo "Hostname: $(hostname)"
            echo "IP: $(hostname -I | awk '{print $1}')"

            # CI/CD uses Doppler STG config for deployment.
            # NOTE: Doppler reserves env var names like DOPPLER_PROJECT so we keep these as script constants
            # instead of trying to store them as Doppler secrets.
            DOPPLER_PROJECT="portfolio-api"
            # Primary: CI/CD "stg" config (per your current setup).
            # Fallback: "prd" config (common when the service token only has PRD access).
            DOPPLER_CONFIG_PRIMARY="stg"
            DOPPLER_CONFIG_FALLBACK="prd"

            # Install Doppler CLI if not exists
            if ! command -v doppler &> /dev/null; then
              echo "Installing Doppler CLI..."
              curl -Ls --tlsv1.2 --proto "=https" --write-out "Installed Doppler CLI %{http_code}\n" -o /tmp/install.sh https://cli.doppler.com/install.sh
              sh /tmp/install.sh
              export PATH="/usr/local/bin:$PATH"
            fi

            # Login to ACR
            echo "Logging into Azure Container Registry..."
            echo "$ACR_PASSWORD" | docker login "$ACR_LOGIN_SERVER" -u "$ACR_USERNAME" --password-stdin

            # Pull latest image
            echo "Pulling Docker image: $ACR_LOGIN_SERVER/$ACR_REPOSITORY:main"
            docker pull "$ACR_LOGIN_SERVER/$ACR_REPOSITORY:main"

            # Stop and remove old container
            echo "Stopping old container..."
            docker stop kb-api 2>/dev/null || true
            docker rm kb-api 2>/dev/null || true

            # Fetch secrets from Doppler into a temp env-file and pass it to the container.
            # NOTE: `doppler run -- docker run ...` does NOT automatically inject env vars into the container.
            # Docker only gets env vars you pass explicitly via `-e/--env` or `--env-file`.
            tmp_env="$(mktemp /tmp/kb-api.env.XXXXXX)"
            chmod 600 "$tmp_env"
            trap 'rm -f "$tmp_env"' EXIT

            echo "Downloading Doppler secrets (project=$DOPPLER_PROJECT config=$DOPPLER_CONFIG_PRIMARY) to env-file..."
            if ! doppler secrets download \
              --project "$DOPPLER_PROJECT" \
              --config "$DOPPLER_CONFIG_PRIMARY" \
              --format docker \
              --no-file \
              --token "$DOPPLER_TOKEN" > "$tmp_env"; then
              echo "WARN: Doppler download failed for config '$DOPPLER_CONFIG_PRIMARY'. Trying fallback '$DOPPLER_CONFIG_FALLBACK'..."
              doppler secrets download \
                --project "$DOPPLER_PROJECT" \
                --config "$DOPPLER_CONFIG_FALLBACK" \
                --format docker \
                --no-file \
                --token "$DOPPLER_TOKEN" > "$tmp_env"
            fi

            # If DATABASE_URL in Doppler points to an unreachable private subnet for this host,
            # automatically provision a local pgvector Postgres and override DATABASE_URL.
            DOCKER_NETWORK_ARGS=""
            use_local_db="0"
            db_url="$(grep -E '^DATABASE_URL=' "$tmp_env" | head -n1 | sed 's/^DATABASE_URL=//')"
            if [ -z "$db_url" ]; then
              echo "WARN: DATABASE_URL missing from Doppler secrets; will use local pgvector DB."
              use_local_db="1"
            else
              # Avoid printing credentials.
              if command -v python3 >/dev/null 2>&1; then
                py=python3
              else
                py=python
              fi
              read -r db_host db_port db_name <<< "$($py -c "from urllib.parse import urlparse; import sys; u=urlparse(sys.argv[1]); print(u.hostname or '', u.port or 5432, (u.path or '')[1:])" "$db_url")"
              echo "DATABASE_URL target (masked): host=$db_host port=$db_port db=$db_name"

              # Quick TCP reachability test from the host (matches container routing expectations here).
              if timeout 3 bash -lc "cat < /dev/null > /dev/tcp/$db_host/$db_port" 2>/dev/null; then
                echo "Database is reachable from this host."
              else
                echo "WARN: Database is NOT reachable from this host (host=$db_host port=$db_port). Falling back to local pgvector DB."
                use_local_db="1"
              fi
            fi

            if [ "$use_local_db" = "1" ]; then
              DEPLOY_DIR="$HOME/.kb-api"
              mkdir -p "$DEPLOY_DIR"
              pw_file="$DEPLOY_DIR/.postgres_password"
              if [ -f "$pw_file" ]; then
                POSTGRES_PASSWORD="$(cat "$pw_file")"
              else
                POSTGRES_PASSWORD="$(openssl rand -hex 16)"
                printf "%s" "$POSTGRES_PASSWORD" > "$pw_file"
                chmod 600 "$pw_file"
              fi

              docker network inspect kb-net >/dev/null 2>&1 || docker network create kb-net

              if docker ps --format '{{.Names}}' | grep -qx 'kb-db'; then
                echo "Local DB container kb-db already running."
              else
                if docker ps -a --format '{{.Names}}' | grep -qx 'kb-db'; then
                  echo "Starting existing local DB container kb-db..."
                  docker start kb-db
                else
                  echo "Starting local pgvector Postgres (kb-db)..."
                  docker run -d \
                    --name kb-db \
                    --restart unless-stopped \
                    --network kb-net \
                    -e POSTGRES_USER=postgres \
                    -e POSTGRES_PASSWORD="$POSTGRES_PASSWORD" \
                    -e POSTGRES_DB=kb \
                    -v kb-db-data:/var/lib/postgresql/data \
                    pgvector/pgvector:pg16
                fi
              fi

              echo "Waiting for kb-db to be ready..."
              for i in $(seq 1 30); do
                if docker exec kb-db pg_isready -U postgres >/dev/null 2>&1; then
                  break
                fi
                sleep 2
              done
              if ! docker exec kb-db pg_isready -U postgres >/dev/null 2>&1; then
                echo "ERROR: kb-db did not become ready. Logs:"
                docker logs --tail 200 kb-db || true
                exit 1
              fi

              # Override DATABASE_URL for kb-api to point at kb-db on the shared network.
              echo "DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@kb-db:5432/kb" >> "$tmp_env"
              DOCKER_NETWORK_ARGS="--network kb-net"
            fi

            echo "Starting new container (env injected via --env-file)..."
            docker run -d \
              --name kb-api \
              --restart unless-stopped \
              -p 8000:8000 \
              $DOCKER_NETWORK_ARGS \
              --env-file "$tmp_env" \
              --health-cmd "curl -f http://localhost:8000/ready || exit 1" \
              --health-interval 30s \
              --health-timeout 10s \
              --health-retries 3 \
              "$ACR_LOGIN_SERVER/$ACR_REPOSITORY:main"

            # Wait for container to be healthy (avoid doing this from GitHub runner which may not reach the host)
            echo "Waiting for container to be healthy..."
            last_health=""
            for i in $(seq 1 18); do
              state="$(docker inspect -f '{{.State.Status}}' kb-api 2>/dev/null || true)"
              health="$(docker inspect -f '{{if .State.Health}}{{.State.Health.Status}}{{else}}none{{end}}' kb-api 2>/dev/null || true)"
              restarts="$(docker inspect -f '{{.RestartCount}}' kb-api 2>/dev/null || true)"
              echo "status=$state health=$health restarts=$restarts (t=$((i*5))s)"
              last_health="$health"

              if [ "$state" != "running" ]; then
                echo "Container is not running. Showing logs:"
                docker logs --tail 200 kb-api || true
                exit 1
              fi

              if [ "$health" = "healthy" ]; then
                break
              fi

              if [ "$health" = "unhealthy" ]; then
                echo "Container reported unhealthy. Showing logs:"
                docker logs --tail 200 kb-api || true
                exit 1
              fi

              sleep 5
            done

            if [ "$last_health" != "healthy" ]; then
              echo "ERROR: Timed out waiting for healthy container. Showing status + logs:"
              docker ps --filter "name=kb-api" || true
              docker logs --tail 200 kb-api || true
              exit 1
            fi

            # Final internal readiness check (fast fail if app can't serve core endpoints)
            curl -fSs http://localhost:8000/ready >/dev/null || {
              echo "ERROR: /ready check failed. Showing logs:"
              docker logs --tail 200 kb-api || true
              exit 1
            }

            # Build/refresh index (cleaned docs are shipped in the image as kb/data/cleaned/docs.jsonl).
            # This ensures the DB actually has data for /search and /ask.
            echo "Running indexing pipeline inside the container..."
            # NOTE: The container image may not have the kb package installed as a console script.
            # Run via module entrypoint instead.
            if ! docker exec -w /app -e PYTHONPATH=/app kb-api python -m kb.cli --stage build; then
              echo "ERROR: Indexing failed. Showing container logs:"
              docker logs --tail 200 kb-api || true
              exit 1
            fi

            # Smoke test core API endpoints on the host
            curl -fSs -X POST http://localhost:8000/search \
              -H "Content-Type: application/json" \
              -d '{"query":"RAG","k":3}' >/dev/null || {
                echo "ERROR: /search smoke test failed. Showing logs:"
                docker logs --tail 200 kb-api || true
                exit 1
              }

            curl -fSs -X POST http://localhost:8000/ask \
              -H "Content-Type: application/json" \
              -d '{"question":"What is RAG?","top_k":3}' >/dev/null || {
                echo "ERROR: /ask smoke test failed. Showing logs:"
                docker logs --tail 200 kb-api || true
                exit 1
              }

            # Check container status
            docker ps --filter "name=kb-api"

            # Cleanup old images
            echo "Cleaning up old Docker images..."
            docker image prune -af --filter "until=24h"

            echo "=== Deployment Complete ==="
            echo "Container logs:"
            docker logs --tail 20 kb-api

      # NOTE: Public healthchecks from the GitHub runner are intentionally omitted.
      # Many deployments are internal-only (behind VPN/Access), so we validate health on the target host instead.
