# KB Pipeline Configuration
# Environment variables can be used as fallbacks using ${VAR:-default} syntax

# Input/Output paths
docs_dir: docs                                    # Input directory with MDX files
output_jsonl: kb/data/cleaned/docs.jsonl          # Output JSONL path (stage 1)

# Chunking configuration
chunking:
  max_section_chars: 2000                          # Max chars before recursive split
  chunk_size: 500                                  # Target chunk size
  chunk_overlap: 80                                # Overlap between chunks

# Embedding configuration
embedding:
  provider: gemini                                 # gemini only
  model: models/embedding-001                      # Gemini: models/embedding-001, models/text-embedding-004

# Gemini API configuration (for embedding provider: gemini)
gemini:
  api_key: ${GEMINI_API_KEY:-}                      # Get from environment variable

# Storage configuration
storage:
  database_url: ${DATABASE_URL:-postgresql://user:password@localhost:5432/kb}
  # Set DATABASE_URL env var in production, e.g.:
  # export DATABASE_URL="postgresql://postgres:password@host:port/dbname"

# Vector store configuration
vector_store:
  table_name: kb_chunks_gemini                      # Table name for embeddings
  batch_size: 32                                    # Batch size for embedding requests

# LLM configuration
llm:
  provider: gemini                                  # gemini (LLM for answer generation)
  model: gemini-2.5-flash                       # Model: gemini-2.0-flash-001, gemini-flash-latest
  api_key: ${GEMINI_API_KEY:-}                      # Get from environment variable
  temperature: 0.3                                  # Low temperature for factual accuracy
  max_tokens: 1024                                  # Max tokens for answer generation

# RAG configuration
rag:
  retrieval:
    top_k: 10                                       # Number of chunks to retrieve
    score_threshold: 0.6                            # Minimum similarity score (raised for better precision)
    max_chunks_per_doc: 3                           # Max chunks from same document
    use_hybrid_search: true                         # Enable hybrid semantic + keyword search
    use_reranking: true                             # Enable heuristic re-ranking
    hybrid_alpha: 0.7                               # Semantic vs keyword weight (0.7 = 70% semantic)

  context:
    max_length: 4000                                # Max characters for context
    include_headings: true                          # Include heading hierarchy

  generation:
    temperature: 0.3                                # LLM temperature
    max_tokens: 1024                                # Max tokens in response

  # Agent orchestration
  agent_orchestration:
    fallback_to_web: true                           # Enable web search fallback
    web_fallback_threshold: 0.3                     # If max score < 0.3, use web
    use_llm_routing: false                          # Use LLM for routing (default: keyword only)

# Web search configuration
web_search:
  provider: tavily                                  # tavily or brave
  api_key: ${TAVILY_API_KEY:-}                     # From Doppler/environment
  max_results: 5                                    # Max search results
  search_depth: basic                               # basic or advanced (Tavily only)
  timeout: 30                                       # Request timeout in seconds

# Docusaurus configuration (for citation URL generation)
docusaurus:
  site_url: "https://docs.yiw.me"                  # Base URL for citation links
